# ğŸ“š Knowledgebase RAG Bot

A fully private, offline AI Research Assistant built with:

- âœ… Retrieval-Augmented Generation (RAG) architecture
- âœ… Local document ingestion (PDF, DOCX, HTML)
- âœ… Local LLM inference via LM Studio (DeepSeek, Mistral, Llama3, etc.)
- âœ… Smart Deep Research Mode (dynamic context handling)
- âœ… Streamlit frontend (for easy chat interface)

> Built to empower serious researchers, traders, analysts, and thinkers with real deep reasoning capabilities â€” 100% offline, 100% under your control.

---

## ğŸš€ Features

- ğŸ“‚ Upload private documents (PDFs, DOCXs, HTMLs)
- ğŸ” Ask quick questions or run full **Deep Research Mode**
- ğŸ“š Retrieve knowledge from hundreds of pages at once
- ğŸ§  Dynamic context limiting (~8K prompt tokens) for stability
- ğŸ’¬ Streamlit Web App (Private frontend)
- ğŸ–¥ï¸ Runs fully local using LM Studio for models
- ğŸ” No OpenAI, No API keys, No external calls â€” full privacy

---

## ğŸ“‚ Project Structure

| Folder/File | Purpose |
|:--|:--|
| `app.py` | Streamlit frontend app |
| `vectorstore_local.py` | Indexing PDFs into local ChromaDB |
| `load_documents.py` | Document loader module |
| `chroma_db/` | (Ignored) Vector database (created locally) |
| `venv/` | (Ignored) Python virtual environment |
| `data/` | (Ignored) Folder where you upload your PDFs |

âœ… `.gitignore` ensures no private files are uploaded.

---

## âš™ï¸ Requirements

- Python 3.10+
- LM Studio running locally (`localhost:1234`)
- Installed models (DeepSeek, Mistral, Llama, Gemma, etc.)
- Streamlit
- Sentence Transformers
- LangChain
- Unstructured (for PDF/Docx parsing)

---

## ğŸ› ï¸ How to Run

1. Clone the repository:

```bash
git clone https://github.com/Biotrioo/knowledgebase-rag-bot.git
cd knowledgebase-rag-bot
